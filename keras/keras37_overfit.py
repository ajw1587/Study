# 과적합: 훈련데이터 셋에 너무 특화되어 있어 test, val에 있어 성능이 떨어지는 현상
# 과적합 방지
'''
1. Data를 늘린다.
2. 피쳐를 줄인다.
3. regulariztion (정규화)
4. DropOut ( 딥러닝 한정 ): Fitting 할때 임의로 노드 일부를 사용하지 않는것
                           train 할때는 Dropout = 0.2면 노드중 0.2를 사용하지 않는다.
                           test 할때는 모든 노드를 사용한다.
                           즉, Fitting 할때 과적합을 방지해준다. (너무 train_data에 치중되지 않도록)
                           
5. 앙상블? 통상 2~5% 향상이 있다고 하는 놈들이 있다. (카더라)
'''